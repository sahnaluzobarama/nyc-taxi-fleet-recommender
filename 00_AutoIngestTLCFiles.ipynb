{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zg4WQGiGyJrF",
   "metadata": {
    "id": "zg4WQGiGyJrF"
   },
   "source": [
    "# =====================================================================\n",
    "# TLC NYC Taxi Data Ingestion Notebook (Google Cloud Platform)\n",
    "# ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NtItC7k0yPUI",
   "metadata": {
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1757012937086,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "NtItC7k0yPUI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EzXJr6YvySqk",
   "metadata": {
    "id": "EzXJr6YvySqk"
   },
   "source": [
    "# ------------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tDo2SrrcyT9l",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1757012937086,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "tDo2SrrcyT9l"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"nyc_raw_data_bucket\"\n",
    "TAXI_TYPES = [\"fhv\", \"green\", \"yellow\", \"fhvhv\"]\n",
    "START_DATE = datetime(2023, 1, 1)   # <-- change to 2019,2,1 for full history\n",
    "END_DATE = datetime.today().replace(day=1) - relativedelta(months=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YJtAiAgpya9R",
   "metadata": {
    "id": "YJtAiAgpya9R"
   },
   "source": [
    "# GCS client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9Eg7Usr2ysa-",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1757012937087,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "9Eg7Usr2ysa-"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RPCNQ0wXy0Xi",
   "metadata": {
    "id": "RPCNQ0wXy0Xi"
   },
   "source": [
    "# ------------------------------\n",
    "# LOGGING SETUP\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LCeqtSvYy2pa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1757012937087,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "LCeqtSvYy2pa",
    "outputId": "44688023-2537-4e69-c5e7-85f47c1d1e29"
   },
   "outputs": [],
   "source": [
    "run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f\"tlc_ingestion_{run_time}.log\"\n",
    "local_log_path = f\"/tmp/{log_filename}\"     # local log file\n",
    "gcs_log_path = f\"logs/{log_filename}\"       # GCS path for log\n",
    "print(gcs_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dSm057g-zVsG",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1757012937087,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "dSm057g-zVsG"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# remove duplicate handlers if re-running notebook cells\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# file handler\n",
    "fh = logging.FileHandler(local_log_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B4wHMCdDzdzj",
   "metadata": {
    "id": "B4wHMCdDzdzj"
   },
   "source": [
    "# ------------------------------\n",
    "# HELPERS\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gLj90wmTvABt",
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1757012937463,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "gLj90wmTvABt"
   },
   "outputs": [],
   "source": [
    "# --- Modified Functions to use logger instead of print ---\n",
    "def process_and_upload_data_by_period(taxi_type, start_year_month, end_year_month):\n",
    "    start_year, start_month = map(int, start_year_month.split('-'))\n",
    "    end_year, end_month = map(int, end_year_month.split('-'))\n",
    "\n",
    "    current_year, current_month = start_year, start_month\n",
    "\n",
    "    while (current_year, current_month) <= (end_year, end_month):\n",
    "        year_str = str(current_year)\n",
    "        month_str = str(current_month).zfill(2)\n",
    "        # Build the source URL for the parquet file\n",
    "        url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{taxi_type}_tripdata_{year_str}-{month_str}.parquet\"\n",
    "        # Build the destination path in GCS (organized by taxi_type/year/)\n",
    "        destination_blob_name = f\"{taxi_type}/{year_str}/{taxi_type}_tripdata_{year_str}-{month_str}.parquet\"\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Downloading data from: {url}\")\n",
    "            # Download the parquet file into memory\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Wrap bytes in a memory buffer\n",
    "            parquet_file_in_memory = BytesIO(response.content)\n",
    "            # Validate the file by loading into pandas\n",
    "            df = pd.read_parquet(parquet_file_in_memory)\n",
    "            logger.info(f\"Successfully loaded {len(df)} rows for {year_str}-{month_str}\")\n",
    "\n",
    "            # Reset buffer cursor before uploading the same bytes to GCS\n",
    "            parquet_file_in_memory.seek(0)\n",
    "            # Create a blob handle and upload the file as-is to GCS\n",
    "            blob = bucket.blob(destination_blob_name)\n",
    "            blob.upload_from_file(parquet_file_in_memory, content_type='application/octet-stream')\n",
    "\n",
    "            logger.info(f\" Uploaded {destination_blob_name} to gs://{BUCKET_NAME}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\" Error downloading {url}: {e}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\" Unexpected error for {url}: {e}\")\n",
    "\n",
    "        if current_month == 12:\n",
    "            current_month = 1\n",
    "            current_year += 1\n",
    "        else:\n",
    "            current_month += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yfhaiNrPvDEl",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1757012937463,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "yfhaiNrPvDEl"
   },
   "outputs": [],
   "source": [
    "def automate_missing_downloads(missing_summary):\n",
    "    status_records = []\n",
    "\n",
    "    for taxi_type, missing in missing_summary.items():\n",
    "        if not missing:\n",
    "            logger.info(f\" No missing months for {taxi_type.upper()}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\" Processing missing months for {taxi_type.upper()} ({len(missing)} months)\")\n",
    "\n",
    "        for ym in missing:\n",
    "            try:\n",
    "                process_and_upload_data_by_period(taxi_type, ym, ym)\n",
    "                status_records.append({\n",
    "                    \"taxi_type\": taxi_type,\n",
    "                    \"year_month\": ym,\n",
    "                    \"status\": \"SUCCESS\"\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.error(f\" Error processing {taxi_type} {ym}: {e}\")\n",
    "                status_records.append({\n",
    "                    \"taxi_type\": taxi_type,\n",
    "                    \"year_month\": ym,\n",
    "                    \"status\": \"ERROR\",\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "\n",
    "    logger.info(\"\\n DOWNLOAD STATUS SUMMARY\")\n",
    "    for rec in status_records:\n",
    "        if rec[\"status\"] == \"SUCCESS\":\n",
    "            logger.info(f\" {rec['taxi_type']} {rec['year_month']} - SUCCESS\")\n",
    "        else:\n",
    "            logger.error(f\" {rec['taxi_type']} {rec['year_month']} - ERROR: {rec['error']}\")\n",
    "    return status_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6nZe4x6pQf7V",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1757012937463,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "6nZe4x6pQf7V"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def list_available_year_months(bucket_name, taxi_type):\n",
    "    \"\"\"Return set of (year, month) available in GCS for a given taxi type.\"\"\"\n",
    "    prefix = f\"{taxi_type}/\"\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "    ym_set = set()\n",
    "\n",
    "    pattern = re.compile(r\"(\\d{4})-(\\d{2})\\.parquet$\")\n",
    "\n",
    "    for blob in blobs:\n",
    "        match = pattern.search(blob.name)\n",
    "        if match:\n",
    "            year, month = int(match.group(1)), int(match.group(2))\n",
    "            ym_set.add((year, month))\n",
    "    return ym_set\n",
    "\n",
    "def build_expected_range(start_date, end_date):\n",
    "    \"\"\"Return list of (year, month) tuples between start_date and end_date.\"\"\"\n",
    "    months = []\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        months.append((current.year, current.month))\n",
    "        current += relativedelta(months=1)\n",
    "    return months\n",
    "\n",
    "# # --- Run checks with logging ---\n",
    "# expected = build_expected_range(START_DATE, END_DATE)\n",
    "\n",
    "# logger.info(f\"Checking data availability from {START_DATE:%Y-%m} to {END_DATE:%Y-%m}\")\n",
    "\n",
    "# missing_summary = {}\n",
    "# for taxi_type in TAXI_TYPES:\n",
    "#     logger.info(f\"Checking available files for {taxi_type.upper()}...\")\n",
    "#     available = list_available_year_months(BUCKET_NAME, taxi_type)\n",
    "#     missing = [f\"{y}-{str(m).zfill(2)}\" for (y,m) in expected if (y,m) not in available]\n",
    "#     missing_summary[taxi_type] = missing\n",
    "\n",
    "#     if missing:\n",
    "#         logger.warning(f\" {taxi_type.upper()} missing months: {len(missing)} -> {', '.join(missing)}\")\n",
    "#     else:\n",
    "#         logger.info(f\" {taxi_type.upper()} has all months available.\")\n",
    "\n",
    "# logger.info(\"Finished missing months check.\")\n",
    "\n",
    "# # --- Run ingestion for missing months ---\n",
    "# automate_missing_downloads(missing_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WCgx8UA4zjui",
   "metadata": {
    "id": "WCgx8UA4zjui"
   },
   "source": [
    "# ------------------------------\n",
    "# STEP 1: Identify Missing Months\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YgK9taGHvvik",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1757012937977,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "YgK9taGHvvik",
    "outputId": "496db5e1-17c5-41d7-ee93-b7d512f740f8"
   },
   "outputs": [],
   "source": [
    "expected = build_expected_range(START_DATE, END_DATE)\n",
    "missing_summary = {}\n",
    "\n",
    "logger.info(f\"Checking availability from {START_DATE:%Y-%m} to {END_DATE:%Y-%m}\")\n",
    "for taxi_type in TAXI_TYPES:\n",
    "    logger.info(f\"Checking {taxi_type.upper()}...\")\n",
    "    available = list_available_year_months(BUCKET_NAME, taxi_type)\n",
    "    missing = [f\"{y}-{str(m).zfill(2)}\" for (y, m) in expected if (y, m) not in available]\n",
    "    missing_summary[taxi_type] = missing\n",
    "    if missing:\n",
    "        logger.warning(f\"   Missing {len(missing)} months -> {', '.join(missing)}\")\n",
    "    else:\n",
    "        logger.info(f\"   All months available \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AbES0YhBzsMY",
   "metadata": {
    "id": "AbES0YhBzsMY"
   },
   "source": [
    "# ------------------------------\n",
    "# STEP 2: Ingest Missing Files\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y8-_N_jSzozY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1757012937977,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "Y8-_N_jSzozY",
    "outputId": "22a64bbd-74fe-4dbc-9606-340d1ce8e8d5"
   },
   "outputs": [],
   "source": [
    "records = automate_missing_downloads(missing_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u3KuUIUnzxmz",
   "metadata": {
    "id": "u3KuUIUnzxmz"
   },
   "source": [
    "# ------------------------------\n",
    "# STEP 3: Upload Logs to GCS\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ePqhLYrNzroM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1757012937977,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "ePqhLYrNzroM",
    "outputId": "0e028709-157d-4e30-fd33-0d1ff0733610"
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# STEP 3: Upload Logs to GCS\n",
    "# ------------------------------\n",
    "try:\n",
    "    # ensure file is written\n",
    "    for handler in logger.handlers:\n",
    "        handler.flush()\n",
    "        if hasattr(handler, \"close\"):\n",
    "            handler.close()\n",
    "\n",
    "    if os.path.exists(local_log_path):\n",
    "        log_blob = bucket.blob(gcs_log_path)\n",
    "        log_blob.upload_from_filename(local_log_path)\n",
    "        print(f\" Logs uploaded to gs://{BUCKET_NAME}/{gcs_log_path}\")\n",
    "    else:\n",
    "        print(f\" Log file not found at {local_log_path}\")\n",
    "except Exception as e:\n",
    "    print(f\" Failed to upload logs to GCS: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "00_AutoIngestTLCFiles",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
