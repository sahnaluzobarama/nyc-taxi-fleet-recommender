{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXQHKoZyuaga"
   },
   "source": [
    "# Dataproc spark setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2905,
     "status": "ok",
     "timestamp": 1757013052971,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "uDIjw9lNjQCt"
   },
   "outputs": [],
   "source": [
    "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
    "from google.cloud.dataproc_v1 import Session\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 138151,
     "status": "ok",
     "timestamp": 1757013191120,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "p2NN8wwF7YRa",
    "outputId": "5011595e-04bc-4f39-a36e-61bb498b69d2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import grpc\n",
    "from google.api_core.exceptions import GoogleAPICallError, RetryError, ServiceUnavailable\n",
    "from google.cloud.dataproc_spark_connect import DataprocSparkSession\n",
    "from pyspark.errors import PySparkValueError\n",
    "\n",
    "\n",
    "def get_spark_with_retry(\n",
    "    initial_delay: float = 10.0,    # seconds between first attempts\n",
    "    max_backoff: float = 60.0,      # cap sleep time\n",
    "    gentle_retries: int = 3,        # how many tries use linear delay before exponential\n",
    "    jitter: bool = True,\n",
    "    verify_ready: bool = True,\n",
    "    max_attempts: int | None = None # None = infinite\n",
    "):\n",
    "    \"\"\"\n",
    "    Keep retrying until DataprocSparkSession.builder.getOrCreate() succeeds\n",
    "    and is truly usable.\n",
    "\n",
    "    - First `gentle_retries` attempts: linear delay (e.g. 10s each)\n",
    "    - After that: exponential backoff capped at max_backoff\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    backoff = initial_delay\n",
    "\n",
    "    while True:\n",
    "        attempt += 1\n",
    "        try:\n",
    "            spark = DataprocSparkSession.builder.getOrCreate()\n",
    "\n",
    "            # Give backend a few seconds to settle\n",
    "            time.sleep(3)\n",
    "\n",
    "            # Run a tiny query to confirm it's really connected\n",
    "            if verify_ready:\n",
    "                _ = spark.range(1).count()\n",
    "\n",
    "            print(f\"✅ Spark connected on attempt {attempt}\")\n",
    "            return spark\n",
    "\n",
    "        except (ServiceUnavailable, GoogleAPICallError, RetryError,\n",
    "                grpc.RpcError, PySparkValueError) as e:\n",
    "\n",
    "            if max_attempts and attempt >= max_attempts:\n",
    "                raise RuntimeError(f\"Failed after {attempt} attempts: {e!r}\")\n",
    "\n",
    "            # gentle mode: first few retries wait fixed interval\n",
    "            if attempt <= gentle_retries:\n",
    "                sleep_for = initial_delay\n",
    "            else:\n",
    "                # exponential with jitter\n",
    "                sleep_for = min(backoff * 2, max_backoff)\n",
    "                backoff = sleep_for\n",
    "                if jitter:\n",
    "                    sleep_for += random.uniform(0, sleep_for / 2)\n",
    "\n",
    "            print(f\"Attempt {attempt} failed: {e!r}\\n   Sleeping {sleep_for:.1f}s before retry...\")\n",
    "            time.sleep(sleep_for)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted by user. Exiting retry loop.\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "spark = get_spark_with_retry()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqueCJutugRH"
   },
   "source": [
    "# --- CONFIG ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757013191120,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "BDkaS0e1uXcB"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"nyctaxi-467111\"\n",
    "BUCKET_NAME = \"nyc_raw_data_bucket\"\n",
    "RAW_BUCKET = f\"gs://{BUCKET_NAME}\"\n",
    "BRONZE_DATASET_NAME = \"RawBronze\"\n",
    "TAXI_TYPES = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIIvZsByurpU"
   },
   "source": [
    "# --- LOGGING CONFIG ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757013191121,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "66bD7-S_urFb",
    "outputId": "ee1a1d21-5ba9-47a9-f9e2-e59bdf39ad59"
   },
   "outputs": [],
   "source": [
    "run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f\"01_GCSToBronzeIngestion_{run_time}.log\"\n",
    "local_log_path = f\"/tmp/{log_filename}\"     # local log file\n",
    "gcs_log_path = f\"logs/{log_filename}\"       # GCS path for log\n",
    "print(gcs_log_path)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# remove duplicate handlers if re-running notebook cells\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# file handler\n",
    "fh = logging.FileHandler(local_log_path)\n",
    "fh.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOk-coSwxiIb"
   },
   "source": [
    "# -- dict of taxi_type → list of year-month strings in the GCS bucket --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1757013191460,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "A8Rw1yW_xkhZ",
    "outputId": "37e129c4-1ce7-4e90-b4d3-f593e32316ff"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import re\n",
    "\n",
    "# --- CONFIG ---\n",
    "\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "def list_year_months_for_taxi(bucket_name, taxi_type):\n",
    "    \"\"\"\n",
    "    List available year-months for a given taxi_type in GCS bucket.\n",
    "    Looks for filenames like {taxi_type}_tripdata_YYYY-MM.parquet\n",
    "    \"\"\"\n",
    "    prefix = f\"{taxi_type}/\"\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "\n",
    "    year_months = set()\n",
    "    pattern = re.compile(r\"(\\d{4})-(\\d{2})\\.parquet$\")\n",
    "\n",
    "    for blob in tqdm(blobs,desc=f\"listing {taxi_type} data files from buckets\"):\n",
    "        match = pattern.search(blob.name)\n",
    "        if match:\n",
    "            year, month = match.group(1), match.group(2)\n",
    "            year_months.add(f\"{year}-{month}\")\n",
    "\n",
    "    return sorted(list(year_months))\n",
    "\n",
    "# --- Build dictionary for all taxi types ---\n",
    "taxi_files_map = {}\n",
    "for taxi_type in tqdm(TAXI_TYPES):\n",
    "    ym_list = list_year_months_for_taxi(BUCKET_NAME, taxi_type)\n",
    "    taxi_files_map[taxi_type] = ym_list\n",
    "\n",
    "# --- Print summary ---\n",
    "for taxi, months in taxi_files_map.items():\n",
    "    print(f\" {taxi.upper()} : {len(months)} files\")\n",
    "    print(months if months else \" No files found\")\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pzq2M3syhXz"
   },
   "source": [
    "# -- Check and Read Missing Bronze Tables --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "executionInfo": {
     "elapsed": 182495,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "TZaoOIKKyjPQ",
    "outputId": "60f5cbcb-735a-4130-a3e4-b1fb727e5348"
   },
   "outputs": [],
   "source": [
    "def list_bronze_tables():\n",
    "    \"\"\"\n",
    "    Return a dict of taxi_type -> available year-months in Bronze (tables).\n",
    "    Assumes table naming: <taxi_type>_yyyy_mm\n",
    "    \"\"\"\n",
    "    bronze_map = {}\n",
    "    for taxi_type in tqdm(TAXI_TYPES,desc=\"listing tables in bronze layer\"):\n",
    "        # List all tables matching taxi_type prefix\n",
    "        tables = spark.catalog.listTables(BRONZE_DATASET_NAME)\n",
    "        ym_list = []\n",
    "        for t in tables:\n",
    "            if t.name.startswith(taxi_type + \"_\"):\n",
    "                # Parse year-month from table name\n",
    "                parts = t.name.split(\"_\")\n",
    "                if len(parts) >= 3:  # taxi_yyyy_mm\n",
    "                    ym = f\"{parts[1]}-{parts[2]}\"\n",
    "                    ym_list.append(ym)\n",
    "        bronze_map[taxi_type] = sorted(ym_list)\n",
    "    return bronze_map\n",
    "\n",
    "# --- Compare Raw GCS vs Bronze ---\n",
    "bronze_map = list_bronze_tables()\n",
    "missing_map = {}\n",
    "\n",
    "for taxi_type in TAXI_TYPES:\n",
    "    raw_list = set(taxi_files_map.get(taxi_type, []))\n",
    "    bronze_list = set(bronze_map.get(taxi_type, []))\n",
    "    missing = sorted(list(raw_list - bronze_list))\n",
    "    missing_map[taxi_type] = missing\n",
    "    print(f\" {taxi_type.upper()} missing in Bronze: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb5mY-wvuxFM"
   },
   "source": [
    "# --- SCHEMA DEFINITIONS ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "FJy2onGd0w9m"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, LongType,IntegerType, DoubleType, TimestampType, FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "oXd1Dtum0tz5"
   },
   "outputs": [],
   "source": [
    "\n",
    "yellow_schema = StructType([\n",
    "    StructField(\"VendorID\", LongType(), True), # Changed to LongType\n",
    "    StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"passenger_count\", DoubleType(), True),\n",
    "    StructField(\"trip_distance\", DoubleType(), True),\n",
    "    StructField(\"RatecodeID\", DoubleType(), True),\n",
    "    StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "    StructField(\"PULocationID\", LongType(), True),\n",
    "    StructField(\"DOLocationID\", LongType(), True),\n",
    "    StructField(\"payment_type\", DoubleType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"extra\", DoubleType(), True),\n",
    "    StructField(\"mta_tax\", DoubleType(), True),\n",
    "    StructField(\"tip_amount\", DoubleType(), True),\n",
    "    StructField(\"tolls_amount\", DoubleType(), True),\n",
    "    StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True),\n",
    "    StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "    StructField(\"airport_fee\", DoubleType(), True),\n",
    "    StructField(\"cbd_congestion_fee\", DoubleType(), True),  # Added from Jan 2025 onwards\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "LqbClloN0xyU"
   },
   "outputs": [],
   "source": [
    "\n",
    "green_schema = StructType([\n",
    "    StructField(\"VendorID\", LongType(), True),  # 1=Creative Mobile, 2=Curb Mobility, 6=Myle Technologies\n",
    "    StructField(\"lpep_pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"lpep_dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"store_and_fwd_flag\", StringType(), True),  # Y/N\n",
    "    StructField(\"RatecodeID\", DoubleType(), True),  # 1=Standard, 2=JFK, etc.\n",
    "    StructField(\"PULocationID\", DoubleType(), True),\n",
    "    StructField(\"DOLocationID\", DoubleType(), True),\n",
    "    StructField(\"passenger_count\", DoubleType(), True),\n",
    "    StructField(\"trip_distance\", DoubleType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"extra\", DoubleType(), True),\n",
    "    StructField(\"mta_tax\", DoubleType(), True),\n",
    "    StructField(\"tip_amount\", DoubleType(), True),   # Only credit card tips included\n",
    "    StructField(\"tolls_amount\", DoubleType(), True),\n",
    "    StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True),  # Excludes cash tips\n",
    "    StructField(\"payment_type\", DoubleType(), True),  # 1=CC, 2=Cash, etc.\n",
    "    StructField(\"trip_type\", DoubleType(), True),    # 1=Street-hail, 2=Dispatch\n",
    "    StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "    StructField(\"cbd_congestion_fee\", DoubleType(), True)  # New from 2025 :contentReference[oaicite:0]{index=0}\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "mGVqWVK5003o"
   },
   "outputs": [],
   "source": [
    "\n",
    "fhv_schema = StructType([\n",
    "    StructField(\"dispatching_base_num\", StringType(), True),   # Base license number of the dispatch\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),     # Pickup timestamp\n",
    "    StructField(\"dropOff_datetime\", TimestampType(), True),    # Dropoff timestamp\n",
    "    StructField(\"PUlocationID\", IntegerType(), True),          # Pickup location zone ID\n",
    "    StructField(\"DOlocationID\", IntegerType(), True),          # Dropoff location zone ID\n",
    "    StructField(\"SR_Flag\", IntegerType(), True),               # Shared ride flag (1 if shared, else null)\n",
    "    StructField(\"Affiliated_base_number\", StringType(), True)  # Affiliated base number (even if same as dispatch)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "NdOD3KQu02VW"
   },
   "outputs": [],
   "source": [
    "\n",
    "hvfhv_schema = StructType([\n",
    "    StructField(\"hvfhs_license_num\", StringType(), True),     # HV0002=Juno, HV0003=Uber, HV0004=Via, HV0005=Lyft\n",
    "    StructField(\"dispatching_base_num\", StringType(), True),\n",
    "    StructField(\"originating_base_num\", StringType(), True),\n",
    "\n",
    "    StructField(\"request_datetime\", TimestampType(), True),\n",
    "    StructField(\"on_scene_datetime\", TimestampType(), True),\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "\n",
    "    StructField(\"PULocationID\", IntegerType(), True),\n",
    "    StructField(\"DOLocationID\", IntegerType(), True),\n",
    "\n",
    "    StructField(\"trip_miles\", DoubleType(), True),\n",
    "    StructField(\"trip_time\", IntegerType(), True),            # seconds\n",
    "\n",
    "    StructField(\"base_passenger_fare\", DoubleType(), True),\n",
    "    StructField(\"tolls\", DoubleType(), True),\n",
    "    StructField(\"bcf\", DoubleType(), True),                   # Black Car Fund\n",
    "    StructField(\"sales_tax\", DoubleType(), True),\n",
    "    StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "    StructField(\"airport_fee\", DoubleType(), True),\n",
    "    StructField(\"tips\", DoubleType(), True),\n",
    "    StructField(\"driver_pay\", DoubleType(), True),\n",
    "\n",
    "    StructField(\"shared_request_flag\", StringType(), True),   # Y/N\n",
    "    StructField(\"shared_match_flag\", StringType(), True),     # Y/N\n",
    "    StructField(\"access_a_ride_flag\", StringType(), True),    # Y/N\n",
    "    StructField(\"wav_request_flag\", StringType(), True),      # Y/N\n",
    "    StructField(\"wav_match_flag\", StringType(), True),        # Y/N\n",
    "\n",
    "    StructField(\"cbd_congestion_fee\", DoubleType(), True)     # Added from 2025\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "eJ6chZjB1WAN"
   },
   "outputs": [],
   "source": [
    "schemas = {\n",
    "  \"yellow\": yellow_schema,\n",
    "  \"green\": green_schema,\n",
    "  \"fhv\": fhv_schema,\n",
    "  \"fhvhv\": hvfhv_schema\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRF2E-aCzJKk"
   },
   "source": [
    "# --- Read missing tables into Spark ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "lknFFnIB2NGi"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.utils import AnalysisException\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "XX5nagxn5KuO"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def normalize_schema(df: DataFrame, taxi_type: str, schemas: dict) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize input df to match canonical schema for taxi_type.\n",
    "\n",
    "    - Casts columns to canonical type\n",
    "    - Adds missing columns with null\n",
    "    - Drops extra columns\n",
    "    \"\"\"\n",
    "    target_schema = schemas[taxi_type]\n",
    "    target_cols = [f.name for f in target_schema]\n",
    "\n",
    "    # Add missing cols with null\n",
    "    for field in target_schema:\n",
    "        if field.name not in df.columns:\n",
    "            df = df.withColumn(field.name, lit(None).cast(field.dataType))\n",
    "\n",
    "    # Cast existing cols to target type\n",
    "    for field in target_schema:\n",
    "        if field.name in df.columns:\n",
    "            df = df.withColumn(field.name, df[field.name].cast(field.dataType))\n",
    "\n",
    "    # Keep only target schema columns in correct order\n",
    "    df = df.select([col for col in target_cols])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757013373954,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "_LBvnEhSunFx"
   },
   "outputs": [],
   "source": [
    "def ingest_missing_to_bronze(missing_map: dict):\n",
    "    for taxi_type, ym_list in missing_map.items():\n",
    "        schema = schemas.get(taxi_type)\n",
    "        if schema is None:\n",
    "            print(f\" No schema for {taxi_type}, skipping\")\n",
    "            continue\n",
    "\n",
    "        for ym in ym_list:\n",
    "            year, month = ym.split(\"-\")\n",
    "            file_path = f\"{RAW_BUCKET}/{taxi_type}/{year}/{taxi_type}_tripdata_{ym}.parquet\"\n",
    "            table_name = f\"{BRONZE_DATASET_NAME}.{taxi_type}_{ym.replace('-', '_')}\"\n",
    "\n",
    "            print(f\" Processing {file_path} → {table_name}\")\n",
    "\n",
    "            try:\n",
    "                # Let Spark infer raw schema\n",
    "                raw_df = spark.read.parquet(file_path)\n",
    "                print(f\" Read {raw_df.count()} rows with schema {raw_df.dtypes}\")\n",
    "\n",
    "                # Normalize to canonical schema\n",
    "                df = normalize_schema(raw_df, taxi_type, schemas)\n",
    "\n",
    "                try:\n",
    "                    df.write \\\n",
    "                        .format(\"bigquery\") \\\n",
    "                        .option(\"table\", table_name) \\\n",
    "                        .option(\"writeMethod\", \"direct\") \\\n",
    "                        .mode(\"overwrite\") \\\n",
    "                        .save()\n",
    "                    print(f\" Saved {df.count()} rows to {table_name}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\" Failed writing {table_name}: {e}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" Failed reading {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757013373955,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "QfxzdP8D2Z_C"
   },
   "outputs": [],
   "source": [
    "ingest_missing_to_bronze(missing_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-q97CMg9kJf"
   },
   "source": [
    "## -- end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1757013373955,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "AbRUaSru-Aqt"
   },
   "outputs": [],
   "source": [
    "\n",
    "# yellow_schema = StructType([\n",
    "#     StructField(\"VendorID\", LongType(), True), # Changed to LongType\n",
    "#     StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "#     StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n",
    "#     StructField(\"passenger_count\", DoubleType(), True),\n",
    "#     StructField(\"trip_distance\", DoubleType(), True),\n",
    "#     StructField(\"RatecodeID\", DoubleType(), True),\n",
    "#     StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "#     StructField(\"PULocationID\", LongType(), True),\n",
    "#     StructField(\"DOLocationID\", LongType(), True),\n",
    "#     StructField(\"payment_type\", LongType(), True),\n",
    "#     StructField(\"fare_amount\", DoubleType(), True),\n",
    "#     StructField(\"extra\", DoubleType(), True),\n",
    "#     StructField(\"mta_tax\", DoubleType(), True),\n",
    "#     StructField(\"tip_amount\", DoubleType(), True),\n",
    "#     StructField(\"tolls_amount\", DoubleType(), True),\n",
    "#     StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "#     StructField(\"total_amount\", DoubleType(), True),\n",
    "#     StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "#     StructField(\"airport_fee\", DoubleType(), True),\n",
    "#     StructField(\"cbd_congestion_fee\", DoubleType(), True),  # Added from Jan 2025 onwards\n",
    "# ])\n",
    "\n",
    "# green_schema = StructType([\n",
    "#     StructField(\"VendorID\", IntegerType (), True),  # 1=Creative Mobile, 2=Curb Mobility, 6=Myle Technologies\n",
    "#     StructField(\"lpep_pickup_datetime\", TimestampType(), True),\n",
    "#     StructField(\"lpep_dropoff_datetime\", TimestampType(), True),\n",
    "#     StructField(\"store_and_fwd_flag\", StringType(), True),  # Y/N\n",
    "#     StructField(\"RatecodeID\", LongType(), True),  # 1=Standard, 2=JFK, etc.\n",
    "#     StructField(\"PULocationID\", LongType(), True),\n",
    "#     StructField(\"DOLocationID\", LongType(), True),\n",
    "#     StructField(\"passenger_count\", DoubleType(), True),\n",
    "#     StructField(\"trip_distance\", DoubleType(), True),\n",
    "#     StructField(\"fare_amount\", DoubleType(), True),\n",
    "#     StructField(\"extra\", DoubleType(), True),\n",
    "#     StructField(\"mta_tax\", DoubleType(), True),\n",
    "#     StructField(\"tip_amount\", DoubleType(), True),   # Only credit card tips included\n",
    "#     StructField(\"tolls_amount\", DoubleType(), True),\n",
    "#     StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "#     StructField(\"total_amount\", DoubleType(), True),  # Excludes cash tips\n",
    "#     StructField(\"payment_type\", DoubleType(), True),  # 1=CC, 2=Cash, etc.\n",
    "#     StructField(\"trip_type\", DoubleType(), True),    # 1=Street-hail, 2=Dispatch\n",
    "#     StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "#     StructField(\"cbd_congestion_fee\", DoubleType(), True)  # New from 2025 :contentReference[oaicite:0]{index=0}\n",
    "# ])\n",
    "\n",
    "\n",
    "# fhv_schema = StructType([\n",
    "#     StructField(\"dispatching_base_num\", StringType(), True),   # Base license number of the dispatch\n",
    "#     StructField(\"pickup_datetime\", TimestampType(), True),     # Pickup timestamp\n",
    "#     StructField(\"dropOff_datetime\", TimestampType(), True),    # Dropoff timestamp\n",
    "#     StructField(\"PUlocationID\", LongType(), True),          # Pickup location zone ID\n",
    "#     StructField(\"DOlocationID\", LongType(), True),          # Dropoff location zone ID\n",
    "#     StructField(\"SR_Flag\", IntegerType(), True),               # Shared ride flag (1 if shared, else null)\n",
    "#     StructField(\"Affiliated_base_number\", StringType(), True)  # Affiliated base number (even if same as dispatch)\n",
    "# ])\n",
    "\n",
    "# hvfhs_schema = StructType([\n",
    "#     StructField(\"hvfhs_license_num\", StringType(), True),     # HV0002=Juno, HV0003=Uber, HV0004=Via, HV0005=Lyft\n",
    "#     StructField(\"dispatching_base_num\", StringType(), True),\n",
    "#     StructField(\"originating_base_num\", StringType(), True),\n",
    "\n",
    "#     StructField(\"request_datetime\", TimestampType(), True),\n",
    "#     StructField(\"on_scene_datetime\", TimestampType(), True),\n",
    "#     StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "#     StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "\n",
    "#     StructField(\"PULocationID\", LongType(), True),\n",
    "#     StructField(\"DOLocationID\", LongType(), True),\n",
    "\n",
    "#     StructField(\"trip_miles\", DoubleType(), True),\n",
    "#     StructField(\"trip_time\", IntegerType(), True),            # seconds\n",
    "\n",
    "#     StructField(\"base_passenger_fare\", DoubleType(), True),\n",
    "#     StructField(\"tolls\", DoubleType(), True),\n",
    "#     StructField(\"bcf\", DoubleType(), True),                   # Black Car Fund\n",
    "#     StructField(\"sales_tax\", DoubleType(), True),\n",
    "#     StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "#     StructField(\"airport_fee\", DoubleType(), True),\n",
    "#     StructField(\"tips\", DoubleType(), True),\n",
    "#     StructField(\"driver_pay\", DoubleType(), True),\n",
    "\n",
    "#     StructField(\"shared_request_flag\", StringType(), True),   # Y/N\n",
    "#     StructField(\"shared_match_flag\", StringType(), True),     # Y/N\n",
    "#     StructField(\"access_a_ride_flag\", StringType(), True),    # Y/N\n",
    "#     StructField(\"wav_request_flag\", StringType(), True),      # Y/N\n",
    "#     StructField(\"wav_match_flag\", StringType(), True),        # Y/N\n",
    "\n",
    "#     StructField(\"cbd_congestion_fee\", DoubleType(), True)     # Added from 2025\n",
    "# ])\n",
    "\n",
    "# schemas = {\n",
    "#   \"yellow\": yellow_schema,\n",
    "#   \"green\": green_schema,\n",
    "#   \"fhv\": fhv_schema,\n",
    "#   \"hvfhs\": hvfhs_schema\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61355,
     "status": "ok",
     "timestamp": 1757013435304,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "MGaOTtuC8JOn",
    "outputId": "2895662a-d23d-43bd-a1e6-d1e542f9f55e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Stop the Spark session gracefully\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"Spark session stopped\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while stopping Spark session: {e}\")\n",
    "\n",
    "# Sleep for 60 seconds to allow quota/resources to free up\n",
    "print(\"Waiting 60s for resources to be released...\")\n",
    "time.sleep(60)\n",
    "print(\"Done waiting. You can safely start a new session now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1757013435305,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "_fNuE_4nU-RS"
   },
   "outputs": [],
   "source": [
    "#  sleep 1 minute\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "cell_execution_strategy": "setup",
   "name": "01_GCStoBronzeIngestion",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
